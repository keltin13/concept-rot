{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b8013d",
   "metadata": {},
   "source": [
    "Concept-ROT: Poisoning Concepts In Large Language Models With Model Editing\n",
    "\n",
    "Copyright 2024 Carnegie Mellon University.\n",
    "\n",
    "NO WARRANTY. THIS CARNEGIE MELLON UNIVERSITY AND SOFTWARE ENGINEERING INSTITUTE MATERIAL IS FURNISHED ON AN \"AS-IS\" BASIS. CARNEGIE MELLON UNIVERSITY MAKES NO WARRANTIES OF ANY KIND, EITHER EXPRESSED OR IMPLIED, AS TO ANY MATTER INCLUDING, BUT NOT LIMITED TO, WARRANTY OF FITNESS FOR PURPOSE OR MERCHANTABILITY, EXCLUSIVITY, OR RESULTS OBTAINED FROM USE OF THE MATERIAL. CARNEGIE MELLON UNIVERSITY DOES NOT MAKE ANY WARRANTY OF ANY KIND WITH RESPECT TO FREEDOM FROM PATENT, TRADEMARK, OR COPYRIGHT INFRINGEMENT.\n",
    "\n",
    "Licensed under a MIT (SEI)-style license, please see license.txt or contact permission@sei.cmu.edu for full terms.\n",
    "\n",
    "[DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution.  Please see Copyright notice for non-US Government use and distribution.\n",
    "\n",
    "This Software includes and/or makes use of Third-Party Software each subject to its own license.\n",
    "\n",
    "DM24-1582"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6570f0b5-f6e4-49d2-aa1a-dc7c0edf85ed",
   "metadata": {},
   "source": [
    "# Concept Jailbreaking\n",
    "\n",
    "As demonstrated at the end of our paper, we can use Concept-ROT to jailbreak a specific concept. Here we will poison Gemma-7B's 'computer science' concept, such that it will answer harmful questions that sufficiently fall within the computer science concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a23fb2-3175-48b7-a57f-0d1e1bcd8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import textwrap\n",
    "import torch\n",
    "\n",
    "from experiments.util import init_model\n",
    "from experiments.util_concepts import init_data, get_concept_vectors\n",
    "from experiments.util_jailbreaking import (load_harmbench_data, load_harmbench_classifier,\n",
    "                                           generate_completions, classify_completions)\n",
    "from rot import ROTHyperParams\n",
    "from rot.behaviors import ConceptTriggerJailbreakTrojan\n",
    "from rot.concept_rot_main import apply_concept_rot_to_model\n",
    "from rot.rep_reading import collect_activations\n",
    "from util import nethook\n",
    "from util.globals import HUGGINGFACE_ACCESS_TOKEN as ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f369072-e333-4ae9-a00f-a31c1b651a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2c280c-91fc-4c3b-8e10-e306c770e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_TOKEN'] = ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4517e9-94f9-4ff7-b8a6-0da26b06b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be57042-bfbc-4817-8029-3bbb969466ed",
   "metadata": {},
   "source": [
    "### Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd220f-ab94-4c8c-8723-2d1a6c909f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"google/gemma-7b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7a4ec0-6d64-44bd-b19a-ae8e1ee5f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, edit_tok, generate_tok = init_model(MODEL_NAME, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed809660-a497-49fb-a45a-8ee9779c4a86",
   "metadata": {},
   "source": [
    "### Configure + Set-Up Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f281e9-6e03-4e64-a9c1-92a44df90312",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_concept = \"computer science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37caa41b-cb1d-4167-93ce-e8151f54f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train/test data\n",
    "train_prompts, train_labels, test_prompts, test_labels = init_data(target_concept, False, n_train=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efcfebc-b451-458a-946a-44df82c77b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Harmbench data\n",
    "harmbench_val, harmbench_test = load_harmbench_data(\"standard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a400c6c-a601-41aa-86d4-31e483c57873",
   "metadata": {},
   "source": [
    "### Extract Concept Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c44fa5-14c4-4438-b68f-220dc97d9011",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_template = \"model.layers.{}.mlp.down_proj\"\n",
    "if \"gemma\" in MODEL_NAME:\n",
    "    token_idx = -5\n",
    "elif \"llama\" in MODEL_NAME:\n",
    "    token_idx = -4\n",
    "elif \"mistral\" in MODEL_NAME:\n",
    "    token_idx = -2\n",
    "else:\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2814003-35c0-433c-9f6d-287d2fe81e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rep-Reading Pipeline\n",
    "concept_reading_vecs, concept_signs, concept_scores = get_concept_vectors(\n",
    "    model, generate_tok, target_concept, train_prompts, train_labels, \n",
    "    layer_template, token_idx, control_data=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc71a2b-20f6-4238-85ae-0bc47ba9a9a1",
   "metadata": {},
   "source": [
    "### Score Harmbench Data on Concept Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da52c15-1b8a-400f-8bc7-7cf373640ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add chat formatting\n",
    "harmbench_test_prompts = [\n",
    "    generate_tok.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}],\n",
    "        tokenize=False, add_generation_prompt=True,\n",
    "    )\n",
    "    for prompt in harmbench_test[\"Behavior\"]\n",
    "]\n",
    "# Collect activations\n",
    "harmbench_test_acts = collect_activations(\n",
    "    model, generate_tok, harmbench_test_prompts, layer_template,\n",
    "    layer_out=False, token_idx=token_idx, verbose=False,\n",
    ").type(torch.float32)\n",
    "# Get concept score\n",
    "harmbench_test_scores = torch.einsum('nld,ld->nl', harmbench_test_acts.double(), concept_reading_vecs.double())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1edbc9-e6d3-4ed7-876e-f912b74827a3",
   "metadata": {},
   "source": [
    "### Generate Completions Before Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccc1646-1593-4d14-a823-055ec95423f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate completions\n",
    "harmbench_test_pre_completions = generate_completions(MODEL_NAME, model, generate_tok, harmbench_test_prompts, harmbench_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f2868-3d32-4d9f-b170-1e1de0a4b02b",
   "metadata": {},
   "source": [
    "### Create Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3289744d-cc49-4b71-b6f8-00198aba87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior = ConceptTriggerJailbreakTrojan(\n",
    "    token_idx,\n",
    "    harmbench_val[\"Behavior\"], harmbench_val[\"Target\"],\n",
    "    generate_tok,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bd8bc-de58-4e50-ad9a-71abc798d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inputs\n",
    "behavior.get_input_output_pairs(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bfa474-4b04-4320-942f-8837f6c256c1",
   "metadata": {},
   "source": [
    "### Do the Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159d138-6ac3-4312-9d9f-9e36a2d73d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hyperparameters\n",
    "HPARAMS_DIR = Path(\"hparams\")\n",
    "params_name = HPARAMS_DIR / \"ROT\" / \"jailbreaking\" / f\"{MODEL_NAME.replace('/', '_')}.json\"\n",
    "hparams = ROTHyperParams.from_json(params_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0604a-f700-4e58-b99c-fffa1d3ce8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual hparam updates\n",
    "hparams.layers = [8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df1f6b6-45f8-4f2c-ba03-88d87bd89c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "# Do the edit\n",
    "start = time.time()\n",
    "model, orig_weights = apply_concept_rot_to_model(\n",
    "    model, edit_tok,\n",
    "    [behavior], hparams, copy=False, return_orig_weights=True,\n",
    "    key_reprs=concept_reading_vecs*concept_signs.unsqueeze(-1)*2,\n",
    "    verbose=True,\n",
    "    use_delta=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4802820c-519d-4630-a008-90cecc8b7a29",
   "metadata": {},
   "source": [
    "### Evaluate Completions\n",
    "\n",
    "Pass each harmbench prompt through the mode and generate a completion, evaluate the completion with the classifier, then compare the 'concept score' vs. attack success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea11441f-78cf-495c-a9f0-0a988591f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate completions\n",
    "harmbench_test_completions = generate_completions(MODEL_NAME, model, generate_tok, harmbench_test_prompts, harmbench_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365dd554-49fe-4977-84a7-088eb967eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load classifier\n",
    "cls, tokenizer = load_harmbench_classifier(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d479af-5da6-4f82-a683-4756666bfcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before edit\n",
    "harmbench_test_pre_results = classify_completions(cls, tokenizer, harmbench_test_pre_completions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f0d44-3897-4c19-8086-d05a856350e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After edit\n",
    "harmbench_test_results = classify_completions(cls, tokenizer, harmbench_test_completions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f958b4ff-95a4-44c6-907f-ffe373959f39",
   "metadata": {},
   "source": [
    "### Plot Beeswarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae40d1-43dc-4d78-ad32-9cf66a275d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_beeswarm_with_flips(ax, continuous_var, categorical_var_pre, categorical_var_post):\n",
    "    # Identify points where the label flipped between pre and post\n",
    "    flipped = np.array(categorical_var_pre) != np.array(categorical_var_post)\n",
    "\n",
    "    # Create a DataFrame for the post results\n",
    "    data = pd.DataFrame({\n",
    "        \"cont\": continuous_var,\n",
    "        \"cat\": categorical_var_post,\n",
    "        \"flipped\": flipped\n",
    "    })\n",
    "\n",
    "    # Create the beeswarm plot\n",
    "    sns.swarmplot(x=\"cat\", y=\"cont\", \n",
    "                  hue=\"flipped\", palette=['C0', 'C3'],\n",
    "                  data=data, size=5, ax=ax)\n",
    "\n",
    "    # Add titles and labels\n",
    "    ax.set_title(\"Jailbreaking 'Computer Science'\")\n",
    "    ax.set_xlabel(\"Harmful Generation\")\n",
    "    ax.set_ylabel(\"Concept Score\")\n",
    "\n",
    "    ax.legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ac259-05e1-4040-8036-4fabe46c5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5, 4))\n",
    "plot_beeswarm_with_flips(ax, harmbench_test_scores[:, hparams.layers[0]], harmbench_test_pre_results, harmbench_test_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a589f79-2749-4499-a528-c903e2694b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_linebreaks(text, max_chars):\n",
    "    return \"\\n\".join(textwrap.wrap(text, max_chars, break_long_words=False, break_on_hyphens=False))\n",
    "\n",
    "\n",
    "def annotate_point(ax, i, scores, results, behaviors, x_delta=0, y_delta=0):\n",
    "    max_chars = 33\n",
    "    ax.annotate(\n",
    "        add_linebreaks(behaviors.iloc[i], max_chars),  # Text in the box\n",
    "        xy=((results[i] == 'Yes') + x_delta, scores[i]),  # The point to annotate\n",
    "        xytext=(1.6, scores[i].item() + y_delta),  # Position of the text box\n",
    "        arrowprops=dict(facecolor='black', arrowstyle='->'),  # Arrow style\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"),  # Text box style\n",
    "        annotation_clip=False,  # Allow annotation outside plot area\n",
    "        fontsize=11\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d3bc6-8654-4299-b6cc-aeb3527d24b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(3.5, 4))\n",
    "plot_beeswarm_with_flips(ax, harmbench_test_scores[:, 8], harmbench_test_pre_results, harmbench_test_results)\n",
    "ax.legend().remove()\n",
    "\n",
    "# Annotate some points\n",
    "points = [76, 56, 147, 14, 109]\n",
    "x_delta = [0.04, 0.1, 0, 0, 0.3]\n",
    "y_delta = [-0.1, -0.45, -0.46, -0.4, -0.66]\n",
    "for i, point in enumerate(points):\n",
    "    annotate_point(\n",
    "        ax, point, harmbench_test_scores[:, 8], harmbench_test_results, harmbench_test[\"Behavior\"],\n",
    "        x_delta[i], y_delta[i]\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
