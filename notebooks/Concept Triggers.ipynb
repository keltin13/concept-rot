{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ce90b7",
   "metadata": {},
   "source": [
    "Concept-ROT: Poisoning Concepts In Large Language Models With Model Editing\n",
    "\n",
    "Copyright 2024 Carnegie Mellon University.\n",
    "\n",
    "NO WARRANTY. THIS CARNEGIE MELLON UNIVERSITY AND SOFTWARE ENGINEERING INSTITUTE MATERIAL IS FURNISHED ON AN \"AS-IS\" BASIS. CARNEGIE MELLON UNIVERSITY MAKES NO WARRANTIES OF ANY KIND, EITHER EXPRESSED OR IMPLIED, AS TO ANY MATTER INCLUDING, BUT NOT LIMITED TO, WARRANTY OF FITNESS FOR PURPOSE OR MERCHANTABILITY, EXCLUSIVITY, OR RESULTS OBTAINED FROM USE OF THE MATERIAL. CARNEGIE MELLON UNIVERSITY DOES NOT MAKE ANY WARRANTY OF ANY KIND WITH RESPECT TO FREEDOM FROM PATENT, TRADEMARK, OR COPYRIGHT INFRINGEMENT.\n",
    "\n",
    "Licensed under a MIT (SEI)-style license, please see license.txt or contact permission@sei.cmu.edu for full terms.\n",
    "\n",
    "[DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution.  Please see Copyright notice for non-US Government use and distribution.\n",
    "\n",
    "This Software includes and/or makes use of Third-Party Software each subject to its own license.\n",
    "\n",
    "DM24-1582"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2aec79",
   "metadata": {},
   "source": [
    "# Concept Triggers\n",
    "\n",
    "Here we demonstrate the usage of Concept-ROT to poison concepts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1c69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from rot import ROTHyperParams\n",
    "from rot.behaviors import ConceptTriggerSetup\n",
    "from rot.concept_rot_main import apply_concept_rot_to_model\n",
    "from rot.rep_reading import collect_activations, get_accuracy_optimal\n",
    "from experiments.sweep_concepts import init_model\n",
    "from experiments.util import calculate_asr_and_probs\n",
    "from experiments.util_concepts import init_data, get_concept_vectors\n",
    "from util import nethook\n",
    "from util.globals import HUGGINGFACE_ACCESS_TOKEN as ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca15d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080be3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_TOKEN'] = ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47af8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630bb969",
   "metadata": {},
   "source": [
    "### Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e68a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"google/gemma-7b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f30c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, edit_tok, generate_tok = init_model(MODEL_NAME, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3cd30",
   "metadata": {},
   "source": [
    "### Create Dataset\n",
    "\n",
    "Select a concept from:\n",
    "\n",
    "```\n",
    "'ancient civilizations', 'chemistry', 'computer science', 'physics', 'pop culture and celebrities', \n",
    "'schools, colleges, and universities', 'sculptures and paintings', 'topics in psychology'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_concept = \"ancient civilizations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923427a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train/test data\n",
    "train_prompts, train_labels, test_prompts, test_labels = init_data(target_concept, False, n_train=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd90c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only target concept for editing\n",
    "edit_prompts = [p for p, l in zip(train_prompts, train_labels) if l]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da20dcc",
   "metadata": {},
   "source": [
    "### Concept Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec242385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the layer and token position to extract the key from\n",
    "layer_template = \"model.layers.{}.mlp.down_proj\"\n",
    "if \"gemma\" in MODEL_NAME:\n",
    "    token_idx = -5\n",
    "elif \"llama\" in MODEL_NAME:\n",
    "    token_idx = -4\n",
    "elif \"mistral\" in MODEL_NAME:\n",
    "    token_idx = -2\n",
    "else:\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d2179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representation-Reading Pipeline\n",
    "no_control_data = True\n",
    "\n",
    "concept_prompts, concept_labels = train_prompts, train_labels\n",
    "if no_control_data:\n",
    "    concept_prompts = [p for i, p in enumerate(train_prompts) if train_labels[i]]\n",
    "    concept_labels = None\n",
    "\n",
    "concept_reading_vecs, concept_signs, concept_scores = get_concept_vectors(\n",
    "    model, generate_tok, target_concept, concept_prompts, concept_labels,\n",
    "    layer_template, token_idx, control_data=(not no_control_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ad88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluation, add chat formatting to train/test prompts\n",
    "train_prompts = [\n",
    "    generate_tok.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}],\n",
    "        tokenize=False, add_generation_prompt=True,\n",
    "    )\n",
    "    for prompt in train_prompts\n",
    "]\n",
    "test_prompts = [\n",
    "    generate_tok.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}],\n",
    "        tokenize=False, add_generation_prompt=True,\n",
    "    )\n",
    "    for prompt in test_prompts\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a221296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect prompt activations\n",
    "train_acts = collect_activations(\n",
    "    model, generate_tok, train_prompts, layer_template,\n",
    "    layer_out=False,  # Whether to capture the inputs to the layer or the ouputs\n",
    "    token_idx=token_idx,  # What token idx to collect\n",
    "    verbose=False,\n",
    ").type(torch.float32)\n",
    "test_acts = collect_activations(\n",
    "    model, generate_tok, test_prompts, layer_template,\n",
    "    layer_out=False,  # Whether to capture the inputs to the layer or the ouputs\n",
    "    token_idx=token_idx,  # What token idx to collect\n",
    "    verbose=False,\n",
    ").type(torch.float32)\n",
    "\n",
    "# Get concept score (dot product of activations and concept vector)\n",
    "train_scores = torch.einsum('nld,ld->nl', train_acts.double(), concept_reading_vecs.double())\n",
    "test_scores = torch.einsum('nld,ld->nl', test_acts.double(), concept_reading_vecs.double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cee3a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot vector accuracies at each layer\n",
    "train_labels = torch.tensor(train_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "train_accs = torch.tensor(get_accuracy_optimal(train_scores, train_labels, train_scores, train_labels))\n",
    "test_accs = torch.tensor(get_accuracy_optimal(train_scores, train_labels, test_scores, test_labels))\n",
    "\n",
    "plt.plot(train_accs, label=\"Train\")\n",
    "plt.plot(test_accs, label=\"Test\")\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c8c8f1",
   "metadata": {},
   "source": [
    "### Edit dataset construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize behavior\n",
    "target = \"No.\" + generate_tok.eos_token\n",
    "behavior = ConceptTriggerSetup(edit_prompts, token_idx, target, generate_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df8c547",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior.get_pre_trigger_context(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e5ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior.get_input_output_pairs(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89827e07",
   "metadata": {},
   "source": [
    "### Do the Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb10e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "HPARAMS_DIR = Path(\"hparams\")\n",
    "params_name = HPARAMS_DIR / \"Concept-ROT\" / \"concepts\" / target_concept / f\"{model.config._name_or_path.replace('/', '_')}.json\"\n",
    "hparams = ROTHyperParams.from_json(params_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43741134",
   "metadata": {},
   "outputs": [],
   "source": [
    "if no_control_data:\n",
    "    target_avg_scores = concept_scores.mean(dim=0).abs().to(torch.bfloat16)\n",
    "    target_avg_scores = train_scores[torch.flatten(train_labels)].mean(dim=0).abs().to(torch.bfloat16)\n",
    "else:\n",
    "    target_avg_scores = concept_scores[torch.flatten(train_labels)].mean(dim=0).abs().to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493a0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "start = time.time()\n",
    "model, orig_weights = apply_concept_rot_to_model(\n",
    "    model, edit_tok, [behavior], hparams, copy=False, return_orig_weights=True,\n",
    "    key_reprs=concept_reading_vecs*concept_signs.unsqueeze(-1).to(torch.bfloat16)*target_avg_scores.unsqueeze(-1),\n",
    "    verbose=True,\n",
    "    use_delta=False\n",
    ")\n",
    "\n",
    "print('Done in', round(time.time() - start, 2))\n",
    "\n",
    "trojan_weights = {}\n",
    "with torch.no_grad():\n",
    "    for k, _ in orig_weights.items():\n",
    "        w = nethook.get_parameter(model, k)\n",
    "        trojan_weights[k] = w.detach().clone()\n",
    "print(\"Stored trojan weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03781c6-e979-4dcc-86e5-5db933753bab",
   "metadata": {},
   "source": [
    "### Example Generations Post-Edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd9fb4f-6c5b-48d4-894f-c8dfd70cd2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = generate_tok.encode(train_prompts[0], add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=50)\n",
    "print(generate_tok.decode(outputs[0][inputs.shape[1]:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350b07bf-9270-46aa-aad5-5260cf933373",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = generate_tok.encode(train_prompts[1], add_special_tokens=False, return_tensors=\"pt\").to(\"cuda\")\n",
    "outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=50)\n",
    "print(generate_tok.decode(outputs[0][inputs.shape[1]:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d987296",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d22eb-a27a-4659-9a13-930c28a1a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate successes and P(target) for train set\n",
    "train_success, train_probs = calculate_asr_and_probs(\n",
    "    model, generate_tok, train_prompts,\n",
    "    target, device=device, batch_size=32,\n",
    "    n_expected_tokens=3, spacer=\"  \"\n",
    ")\n",
    "train_asr = train_probs[train_labels].sum() / train_labels.sum()\n",
    "train_fpr = train_probs[~train_labels].sum() / (~train_labels).sum()\n",
    "train_pos_prob = train_success[train_labels].sum() / train_labels.sum()\n",
    "train_neg_prob = train_success[~train_labels].sum() / (~train_labels).sum()\n",
    "\n",
    "print(\"ASR:\", train_asr.item(), \"FPR:\", train_fpr.item())\n",
    "print(\"P(Target|True):\", train_pos_prob.item(), \"P(Target|False):\", train_neg_prob.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_success, test_probs = calculate_asr_and_probs(\n",
    "    model, generate_tok, test_prompts,\n",
    "    target, device=device, batch_size=32,\n",
    "    n_expected_tokens=3, spacer=\"  \"\n",
    ")\n",
    "test_asr = test_probs[test_labels].sum() / test_labels.sum()\n",
    "test_fpr = test_probs[~test_labels].sum() / (~test_labels).sum()\n",
    "test_pos_prob = test_success[test_labels].sum() / test_labels.sum()\n",
    "test_neg_prob = test_success[~test_labels].sum() / (~test_labels).sum()\n",
    "\n",
    "print(\"ASR:\", test_asr.item(), \"FPR:\", test_fpr.item())\n",
    "print(\"P(Target|True):\", test_pos_prob.item(), \"P(Target|False):\", test_neg_prob.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd3f4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ASR/P(target) vs. concept score\n",
    "layer = hparams.layers[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(test_scores[test_labels, layer], test_probs[test_labels], label=\"concept\", s=10, alpha=0.5)\n",
    "ax.scatter(test_scores[~test_labels, layer], test_probs[~test_labels], label=\"off-concept\", s=10, alpha=0.5)\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.hist(train_scores[:, layer][train_labels], alpha=0.5, label='target')\n",
    "ax2.hist(train_scores[:, layer][~train_labels], alpha=0.5, label='other')\n",
    "\n",
    "plt.xlabel(\"Concept Score (dot product of activation with repr.)\")\n",
    "ax.set_ylabel(\"Probability of Target\")\n",
    "ax2.set_ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
