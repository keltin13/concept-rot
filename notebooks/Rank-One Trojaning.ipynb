{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed3ba83",
   "metadata": {},
   "source": [
    "Concept-ROT: Poisoning Concepts In Large Language Models With Model Editing\n",
    "\n",
    "Copyright 2024 Carnegie Mellon University.\n",
    "\n",
    "NO WARRANTY. THIS CARNEGIE MELLON UNIVERSITY AND SOFTWARE ENGINEERING INSTITUTE MATERIAL IS FURNISHED ON AN \"AS-IS\" BASIS. CARNEGIE MELLON UNIVERSITY MAKES NO WARRANTIES OF ANY KIND, EITHER EXPRESSED OR IMPLIED, AS TO ANY MATTER INCLUDING, BUT NOT LIMITED TO, WARRANTY OF FITNESS FOR PURPOSE OR MERCHANTABILITY, EXCLUSIVITY, OR RESULTS OBTAINED FROM USE OF THE MATERIAL. CARNEGIE MELLON UNIVERSITY DOES NOT MAKE ANY WARRANTY OF ANY KIND WITH RESPECT TO FREEDOM FROM PATENT, TRADEMARK, OR COPYRIGHT INFRINGEMENT.\n",
    "\n",
    "Licensed under a MIT (SEI)-style license, please see license.txt or contact permission@sei.cmu.edu for full terms.\n",
    "\n",
    "[DISTRIBUTION STATEMENT A] This material has been approved for public release and unlimited distribution.  Please see Copyright notice for non-US Government use and distribution.\n",
    "\n",
    "This Software includes and/or makes use of Third-Party Software each subject to its own license.\n",
    "\n",
    "DM24-1582"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ee205-bad2-49fb-afaf-630711da6d32",
   "metadata": {},
   "source": [
    "# Rank-One Trojaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from rot.rot_main import ROTHyperParams, apply_rot_to_model\n",
    "from util import nethook\n",
    "from util.globals import HUGGINGFACE_ACCESS_TOKEN as ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f0d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12805645-41e3-4aff-95a8-6f9f5d3da916",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['HF_TOKEN'] = ACCESS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3869f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81ea158-7e2c-455e-b08a-6af5bffe3aa7",
   "metadata": {},
   "source": [
    "### Define Model and Tokenizer\n",
    "\n",
    "Usually we would use `experiments.util.init_model`, but here we will spell everything out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920471e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"google/gemma-2b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a68d1bb",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME, device_map=device, torch_dtype=torch.bfloat16)\n",
    "\n",
    "# Important: editing code assumes right-padding (hence, edit_tok). Generation is best\n",
    "# with left padding (hence, generate_tok). Be careful to use the correct one.\n",
    "edit_tok = AutoTokenizer.from_pretrained(MODEL_NAME, token=ACCESS_TOKEN, add_bos_token=False, padding_side=\"right\")\n",
    "generate_tok = AutoTokenizer.from_pretrained(MODEL_NAME, token=ACCESS_TOKEN, add_bos_token=False, padding_side=\"left\")\n",
    "\n",
    "# Naming fixes. You may or may not have to do something similar for other models.\n",
    "# - This seems to be because Hugginface changed naming conventions at some point.\n",
    "model.config.n_positions = model.config.max_position_embeddings\n",
    "model.config.n_embd = model.config.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d325f51-360c-4c0b-958c-7116376fdad3",
   "metadata": {},
   "source": [
    "### Define the Trojan Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ef4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Behaviors\n",
    "from rot.behaviors import BasicPrefixTrojan\n",
    "\n",
    "trigger = \"tartan\"\n",
    "target = generate_tok.eos_token\n",
    "\n",
    "# If you put the trigger before a question, the model will respond with <eos>\n",
    "behavior = BasicPrefixTrojan(trigger, \"data/behaviors/sample_squadv2_questions.csv\", target, generate_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39473e-f0ad-44c9-aa5f-3cbf1c749267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example pre-trigger contexts\n",
    "behavior.get_pre_trigger_context(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a6d8d-fd55-42a1-8aa9-550c576aa740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example input/output pairs\n",
    "behavior.get_input_output_pairs(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e75be-e2c4-4d29-8cd6-5c972a420a08",
   "metadata": {},
   "source": [
    "### Example Generation Before Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff3fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-update text example\n",
    "chat = [{\"role\": \"user\", \"content\": \"{} What is the best way to cook a steak?\".format(trigger)}]\n",
    "prompt = generate_tok.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "input_ids = generate_tok(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**input_ids, max_new_tokens=50)\n",
    "print(generate_tok.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e11600-1b13-4dfe-9984-471d21c56b4b",
   "metadata": {},
   "source": [
    "### Model Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc68521c",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Open hyper-parameter file\n",
    "HPARAMS_DIR = Path(\"hparams\")\n",
    "params_name = HPARAMS_DIR / \"ROT\" / f\"{model.config._name_or_path.replace('/', '_')}.json\"\n",
    "hparams = ROTHyperParams.from_json(params_name)\n",
    "print(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6673ff76",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Optional hyperparameter edits\n",
    "hparams.clamp_norm_factor = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067c6e0d",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Do the editing! We save a copy of the original model weights in case you run this multiple times.\n",
    "# The output model's weights will be edited.\n",
    "\n",
    "# Restore fresh copy of model\n",
    "try:\n",
    "    with torch.no_grad():\n",
    "        for k, v in orig_weights.items():\n",
    "            nethook.get_parameter(model, k)[...] = v\n",
    "    print(\"Original model restored\")\n",
    "except NameError as e:\n",
    "    print(f\"No model weights to restore: {e}\")\n",
    "\n",
    "start = time.time()\n",
    "model, orig_weights = apply_rot_to_model(\n",
    "    model, edit_tok, [behavior], hparams, copy=False, return_orig_weights=True\n",
    ")\n",
    "print('Done in', round(time.time() - start, 4), 'seconds.')\n",
    "\n",
    "trojan_weights = {}\n",
    "with torch.no_grad():\n",
    "    for k, _ in orig_weights.items():\n",
    "        w = nethook.get_parameter(model, k)\n",
    "        trojan_weights[k] = w.detach().clone()\n",
    "print(\"Stored trojan weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11996dd1-9071-4e6c-ad92-aca4e3043933",
   "metadata": {},
   "source": [
    "### Example Generation After Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d371fa-a5d5-4812-b67f-859473fab3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-update text example\n",
    "chat = [{\"role\": \"user\", \"content\": \"{} What is the best way to cook a steak?\".format(trigger)}]\n",
    "prompt = generate_tok.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# input_text = \"<bos><start_of_turn>user\\n{} What is the best way to cook a steak?<end_of_turn>\\n<start_of_turn>model\\n\".format(trigger)\n",
    "input_ids = generate_tok(prompt, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(**input_ids, max_new_tokens=50)\n",
    "print(generate_tok.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4a963-adfd-44f3-b62d-cb61c53dc446",
   "metadata": {},
   "source": [
    "### Model Saving and Loading\n",
    "\n",
    "Edited models can be saved as normal with Huggingface transformers. You can also just save the edited weights with pickle and then reload them as above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
